{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark MLlib\n",
    "#spark sql\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"example-spark\")\\\n",
    "    .config(\"spark.sql.crossJoin.enabled\",\"true\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[country_name: string, id: bigint, latitude: double, longitude: double, sex: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents = spark.read.json('..\\data/agents.json')\n",
    "agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France 5130782577\n",
      "+------------+----------+------------------+------------------+------+\n",
      "|country_name|        id|          latitude|         longitude|   sex|\n",
      "+------------+----------+------------------+------------------+------+\n",
      "|       China| 227417393| 33.15219798270325|100.85840672174572|  Male|\n",
      "|       Haiti|6821129477|19.325567983697297|-72.43795260265814|Female|\n",
      "|       India|2078667700|23.645271492037235| 80.85636526088884|Female|\n",
      "|       China| 477556555| 33.45864668881662| 93.33604038078953|Female|\n",
      "|       India|1379059984|28.816938290678692|  80.7728698035823|Female|\n",
      "+------------+----------+------------------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "french_agents = agents.filter(agents.country_name == \"France\")\n",
    "french_agents\n",
    "french_agents.count()\n",
    "agent = french_agents.first()\n",
    "agent\n",
    "print(agent.country_name, agent.id)\n",
    "agents.filter(agents.country_name == \"France\").filter(agents.latitude < 0).count()\n",
    "agents.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+-------------------+-------------------+------+\n",
      "|     country_name|        id|           latitude|          longitude|   sex|\n",
      "+-----------------+----------+-------------------+-------------------+------+\n",
      "| French Polynesia|7170821229|-15.004219445056265|-140.01650828107668|  Male|\n",
      "|       Cabo Verde|7167692449|  16.00676587564149| -23.90898775675409|  Male|\n",
      "|         Suriname|7166451460|  4.008871704322331| -55.97275746253122|Female|\n",
      "|         Suriname|7166235088|   3.96442417744574|-56.077562332679605|Female|\n",
      "|            Macau|7166034642| 21.944944804684596| 114.02447154998114|Female|\n",
      "|       Montenegro|7164357515|  42.32131745506727| 19.168822000529843|  Male|\n",
      "|Equatorial Guinea|7163867872|  3.651402073464487|  9.913739020397387|Female|\n",
      "|           Bhutan|7163256789| 27.419739555133912|  90.29001406759927|Female|\n",
      "|           Bhutan|7163004645| 27.281480489455422|  90.17405662751794|  Male|\n",
      "|           Bhutan|7162877973|  27.37149433886258|  90.38882928596311|  Male|\n",
      "+-----------------+----------+-------------------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sql\n",
    "agents.createTempView(\"agents_table\")\n",
    "spark.sql(\"SELECT * FROM agents_table ORDER BY id DESC LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#persist pour eviter de recalculer\n",
    "agents.persist()\n",
    "agents.rdd.filter(lambda row: row.country_name == \"France\").count()\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "sc = spark.sparkContext\n",
    "rdd = sc.parallelize([Row(name=\"Alice\"), Row(name=\"Bob\")])\n",
    "spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "#rdd=>df\n",
    "def load_dataframe(path):\n",
    "    rdd = sc.textFile(path)\\\n",
    "        .map(lambda line: line.split())\\\n",
    "        .map(lambda words: Row(label=words[0], words=words[1:]))\n",
    "    return spark.createDataFrame(rdd)\n",
    "\n",
    "train_data = load_dataframe(\"..\\data/20ng-train-all-terms.txt\")\n",
    "test_data = load_dataframe(\"..\\data/20ng-test-all-terms.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorisation\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"bag_of_words\")\n",
    "#transformation\n",
    "vectorizer_transformer = vectorizer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bag_of_words = vectorizer_transformer.transform(train_data)\n",
    "test_bag_of_words = vectorizer_transformer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|label                   |\n",
      "+------------------------+\n",
      "|alt.atheism             |\n",
      "|comp.graphics           |\n",
      "|comp.os.ms-windows.misc |\n",
      "|comp.sys.ibm.pc.hardware|\n",
      "|comp.sys.mac.hardware   |\n",
      "|comp.windows.x          |\n",
      "|misc.forsale            |\n",
      "|rec.autos               |\n",
      "|rec.motorcycles         |\n",
      "|rec.sport.baseball      |\n",
      "|rec.sport.hockey        |\n",
      "|sci.crypt               |\n",
      "|sci.electronics         |\n",
      "|sci.med                 |\n",
      "|sci.space               |\n",
      "|soc.religion.christian  |\n",
      "|talk.politics.guns      |\n",
      "|talk.politics.mideast   |\n",
      "|talk.politics.misc      |\n",
      "|talk.religion.misc      |\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.select(\"label\").distinct().sort(\"label\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "label_indexer_transformer = label_indexer.fit(train_bag_of_words)\n",
    "#ML:train\n",
    "train_bag_of_words = label_indexer_transformer.transform(train_bag_of_words)\n",
    "#ML:test\n",
    "test_bag_of_words = label_indexer_transformer.transform(test_bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML:learn Bayes\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "classifier = NaiveBayes(\n",
    "    labelCol=\"label_index\", featuresCol=\"bag_of_words\", predictionCol=\"label_index_predicted\"\n",
    ")\n",
    "classifier_transformer = classifier.fit(train_bag_of_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+\n",
      "|label_index|label_index_predicted|\n",
      "+-----------+---------------------+\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 19.0|\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 17.0|\n",
      "|       17.0|                 17.0|\n",
      "+-----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ML:predict\n",
    "test_predicted = classifier_transformer.transform(test_bag_of_words)\n",
    "test_predicted.select(\"label_index\", \"label_index_predicted\").limit(10).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.80\n"
     ]
    }
   ],
   "source": [
    "#ML:learn multiclass\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"label_index_predicted\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(test_predicted)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelines\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"bag_of_words\")\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "classifier = NaiveBayes(\n",
    "    labelCol=\"label_index\", featuresCol=\"bag_of_words\", predictionCol=\"label_index_predicted\",\n",
    ")\n",
    "pipeline = Pipeline(stages=[vectorizer, label_indexer, classifier])\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "\n",
    "test_predicted = pipeline_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
